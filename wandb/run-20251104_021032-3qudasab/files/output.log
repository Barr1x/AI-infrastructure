  0%|                                                                   | 15/9511 [00:08<1:26:58,  1.82it/s]Traceback (most recent call last):
{'loss': 11.0014, 'grad_norm': 4.3125, 'learning_rate': 6.30252100840336e-07, 'epoch': 0.0}
{'loss': 10.9772, 'grad_norm': 4.6875, 'learning_rate': 1.260504201680672e-06, 'epoch': 0.0}
{'loss': 10.999, 'grad_norm': 4.4375, 'learning_rate': 1.8907563025210083e-06, 'epoch': 0.0}
{'loss': 11.0047, 'grad_norm': 4.71875, 'learning_rate': 2.521008403361344e-06, 'epoch': 0.0}
{'loss': 10.9972, 'grad_norm': 4.65625, 'learning_rate': 3.1512605042016808e-06, 'epoch': 0.0}
{'loss': 10.9779, 'grad_norm': 4.8125, 'learning_rate': 3.7815126050420167e-06, 'epoch': 0.0}
{'loss': 10.9976, 'grad_norm': 4.75, 'learning_rate': 4.4117647058823526e-06, 'epoch': 0.0}
{'loss': 10.9894, 'grad_norm': 4.8125, 'learning_rate': 5.042016806722688e-06, 'epoch': 0.0}
{'loss': 10.9796, 'grad_norm': 4.5, 'learning_rate': 5.672268907563024e-06, 'epoch': 0.0}
{'loss': 10.9677, 'grad_norm': 4.6875, 'learning_rate': 6.3025210084033615e-06, 'epoch': 0.0}
{'loss': 10.9691, 'grad_norm': 4.5625, 'learning_rate': 6.932773109243697e-06, 'epoch': 0.0}
{'loss': 10.9477, 'grad_norm': 4.6875, 'learning_rate': 7.563025210084033e-06, 'epoch': 0.0}
{'loss': 10.9229, 'grad_norm': 4.90625, 'learning_rate': 8.193277310924369e-06, 'epoch': 0.0}
{'loss': 10.905, 'grad_norm': 5.09375, 'learning_rate': 8.823529411764705e-06, 'epoch': 0.0}
{'loss': 10.8795, 'grad_norm': 4.96875, 'learning_rate': 9.453781512605041e-06, 'epoch': 0.0}
  File "/home/ubuntu/AI-infrastructure/lm_train.py", line 94, in <module>
    trainer.train()
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/transformers/trainer.py", line 2052, in train
    return inner_training_loop(
           ^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/transformers/trainer.py", line 2388, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/transformers/trainer.py", line 3485, in training_step
    loss = self.compute_loss(model, inputs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/transformers/trainer.py", line 3532, in compute_loss
    outputs = model(**inputs)
              ^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/accelerate/utils/operations.py", line 820, in forward
    return model_forward(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/accelerate/utils/operations.py", line 808, in __call__
    return convert_to_fp32(self.model_forward(*args, **kwargs))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/torch/amp/autocast_mode.py", line 44, in decorate_autocast
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.cache/huggingface/modules/transformers_modules/GPTNeoX-160m/modeling_custom.py", line 1152, in forward
    outputs = self.gpt_neox(
              ^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.cache/huggingface/modules/transformers_modules/GPTNeoX-160m/modeling_custom.py", line 981, in forward
    outputs = layer(
              ^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.cache/huggingface/modules/transformers_modules/GPTNeoX-160m/modeling_custom.py", line 732, in forward
    attention_layer_outputs = self.attention(
                              ^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/miniconda3/envs/cmu-llms-hw4/lib/python3.11/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.cache/huggingface/modules/transformers_modules/GPTNeoX-160m/modeling_custom.py", line 215, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ubuntu/.cache/huggingface/modules/transformers_modules/GPTNeoX-160m/modeling_custom.py", line 340, in _attn
    mask_value = torch.tensor(mask_value, dtype=attn_scores.dtype).to(attn_scores.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
